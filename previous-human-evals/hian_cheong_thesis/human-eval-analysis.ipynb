{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd035e5852f70266fbaa7da3115ae8d9721aa892edaa64c081f6593cce5722f4efd",
   "display_name": "Python 3.9.1 64-bit ('topic-preprocessing': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(inpath):\n",
    "    with open(inpath) as infile:\n",
    "        return json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"news\": load_json(\"news.json\"),\n",
    "    \"leg\": load_json(\"leg.json\"),\n",
    "    \"covid\": load_json(\"covid.json\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "likerts = [\n",
    "    {'dataset': dataset, 'rating_group': who, 'topic': i, 'annotator': j, 'rating': rating}\n",
    "    for dataset, topics in results.items()\n",
    "    for i, topic_data in enumerate(topics)\n",
    "    for who in ['crowdwork_ratings', 'mturk_ratings_data']\n",
    "    for j, rating in enumerate(topic_data[who] if who == 'crowdwork_ratings' else topic_data[who]['answers'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "likerts = pd.DataFrame(likerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      rating          \n",
       "                        mean       std\n",
       "rating_group                          \n",
       "crowdwork_ratings   2.490000  0.640448\n",
       "mturk_ratings_data  2.346667  0.676069"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">rating</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>rating_group</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>crowdwork_ratings</th>\n      <td>2.490000</td>\n      <td>0.640448</td>\n    </tr>\n    <tr>\n      <th>mturk_ratings_data</th>\n      <td>2.346667</td>\n      <td>0.676069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "likerts.groupby([\"rating_group\"]).agg({\"rating\": [\"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "likerts.rating.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(likerts).to_csv(\"likerts.csv\", index=False)"
   ]
  },
  {
   "source": [
    "# Within-topic MTurk-Amazon agreement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    ds: {\n",
    "        \"internal_npmi\": [topic['internal_npmi'] for topic in ds_topics],\n",
    "        \"crowdwork_ratings\": [np.mean(topic[\"crowdwork_ratings\"]) for topic in ds_topics],\n",
    "        \"mturk_ratings\": [np.mean(topic[\"mturk_ratings_data\"][\"answers\"]) for topic in ds_topics],\n",
    "        \"cw\": [np.array(topic[\"crowdwork_ratings\"]) for topic in ds_topics],\n",
    "        \"mturk\": [np.array(topic[\"mturk_ratings_data\"][\"answers\"]) for topic in ds_topics],\n",
    "    }\n",
    "    for ds, ds_topics in results.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "news : Pearson: 0.833*\n",
      "cw internal: 0.860 (0.055)\n",
      "mt internal: 0.662 (0.106)\n",
      "mt cw      : 0.651 (0.141)\n",
      "\n",
      "leg  : Pearson: 0.835*\n",
      "cw internal: 0.671 (0.086)\n",
      "mt internal: 0.504 (0.112)\n",
      "mt cw      : 0.498 (0.109)\n",
      "\n",
      "covid: Pearson: 0.789*\n",
      "cw internal: 0.708 (0.067)\n",
      "mt internal: 0.498 (0.064)\n",
      "mt cw      : 0.491 (0.116)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_runs = 20\n",
    "for ds, ratings in scores.items():\n",
    "    print()\n",
    "    p_r, p_p = pearsonr(ratings['crowdwork_ratings'], ratings['mturk_ratings'])\n",
    "\n",
    "    p_sig = (p_p < 0.01) * \"*\"\n",
    "    print(f\"{ds:5}: Pearson: {p_r:0.3f}{p_sig}\")\n",
    "\n",
    "    # bootstraped internal cor:\n",
    "    bootstrapped = defaultdict(list)\n",
    "    for run in range(n_runs):\n",
    "        cw1_boot = np.array([np.random.choice(topic, size=7) for topic in ratings[\"cw\"]])\n",
    "        cw2_boot = np.array([np.random.choice(topic, size=7) for topic in ratings[\"cw\"]])\n",
    "        mt1_boot = np.array([np.random.choice(topic, size=7) for topic in ratings[\"mturk\"]])\n",
    "        mt2_boot = np.array([np.random.choice(topic, size=7) for topic in ratings[\"mturk\"]])\n",
    "\n",
    "        bootstrapped[\"cw internal\"].append(pearsonr(cw1_boot.mean(1), cw2_boot.mean(1))[0])\n",
    "        bootstrapped[\"mt internal\"].append(pearsonr(mt1_boot.mean(1), mt2_boot.mean(1))[0])\n",
    "        bootstrapped[\"mt cw\"].append(pearsonr(cw1_boot.mean(1), mt1_boot.mean(1))[0])\n",
    "\n",
    "    for k, v in bootstrapped.items():\n",
    "        print(f\"{k:11}: {np.mean(v):0.3f} ({np.std(v):0.3f})\")\n"
   ]
  },
  {
   "source": [
    "## Fleiss' kappa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([2, 2, 1, 3, 2, 2, 1]), array([2, 4, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "for row in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "news , fleiss CW: 0.2189, fleiss MTurk: 0.1014, combin: 0.1532\nleg  , fleiss CW: 0.1133, fleiss MTurk: 0.0665, combin: 0.1347\ncovid, fleiss CW: 0.1838, fleiss MTurk: 0.0390, combin: 0.1531\n"
     ]
    }
   ],
   "source": [
    "def to_fleiss(ratings, min_raters=15):\n",
    "    # subjects by rater -> subjects by category\n",
    "    # basically a pivot\n",
    "    return np.array([np.bincount(row[:min_raters]-1, minlength=3) for row in ratings])\n",
    "\n",
    "for ds, ratings in scores.items():\n",
    "    fleiss_cw = fleiss_kappa(to_fleiss(ratings[\"cw\"]))\n",
    "    fleiss_mt = fleiss_kappa(to_fleiss(ratings[\"mturk\"]))\n",
    "    \n",
    "    combined = [\n",
    "        np.concatenate([\n",
    "            np.random.choice(row_i, size=7),\n",
    "            np.random.choice(row_j, size=7)\n",
    "        ])\n",
    "        for row_i, row_j in zip(ratings[\"cw\"], ratings[\"mturk\"])\n",
    "    ]\n",
    "    fleiss_combined = fleiss_kappa(to_fleiss(combined))\n",
    "\n",
    "    print(f\"{ds:5}, fleiss CW: {fleiss_cw:0.4f}, fleiss MTurk: {fleiss_mt:0.4f}, combin: {fleiss_combined:0.4f}\")"
   ]
  },
  {
   "source": [
    "## Correlations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nnews  crowdwork Pearson: 0.601* Spearman: 0.585*\nnews  mturk     Pearson: 0.584* Spearman: 0.555\n\nleg   crowdwork Pearson: 0.337 Spearman: 0.410*\nleg   mturk     Pearson: 0.270 Spearman: 0.243\n\ncovid crowdwork Pearson: -0.163 Spearman: 0.011\ncovid mturk     Pearson: -0.054 Spearman: -0.004\n"
     ]
    }
   ],
   "source": [
    "n_runs = 20\n",
    "for ds, ratings in scores.items():\n",
    "    print()\n",
    "    for type in [\"crowdwork\", \"mturk\"]:\n",
    "        p_r, p_p = pearsonr(ratings[f'{type}_ratings'], ratings['internal_npmi'])\n",
    "        s_r, s_p = spearmanr(ratings[f'{type}_ratings'], ratings['internal_npmi'])\n",
    "\n",
    "        p_sig = (p_p < 0.01) * \"*\"\n",
    "        s_sig = (s_p < 0.01) * \"*\"\n",
    "        print(f\"{ds:5} {type:9} Pearson: {p_r:0.3f}{p_sig} Spearman: {s_r:0.3f}{s_sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_mlm.py \\\n",
    "--model_name_or_path roberta-base \\\n",
    "--train_file data/20ng/train.txt \\\n",
    "--validation_file data/20ng/test.txt \\\n",
    "--line_by_line \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--num_train_epochs 10 \\\n",
    "--save_steps 1000 \\\n",
    "--output_dir ./models/20ng\n",
    "\n",
    "python run_mlm.py \\\n",
    "--model_name_or_path bert-base-uncased \\\n",
    "--train_file data/20ng/train.txt \\\n",
    "--validation_file data/20ng/test.txt \\\n",
    "--line_by_line \\\n",
    "--wwm \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--num_train_epochs 10 \\\n",
    "--save_steps 1000 \\\n",
    "--output_dir /workspace/transformers/examples/language-modeling/models/20ng-bert-base-uncased-wwm\n",
    "\n",
    "\n",
    "python run_mlm.py \\\n",
    "--model_name_or_path bert-base-uncased \\\n",
    "--train_file data/20ng/train.txt \\\n",
    "--validation_file data/20ng/test.txt \\\n",
    "--line_by_line \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--mlm_prob 0.1 \\\n",
    "--random_word_masking_only \\\n",
    "--num_train_epochs 10 \\\n",
    "--save_steps 1000 \\\n",
    "--output_dir ./models/20ng-random-word-only"
   ]
  }
 ]
}